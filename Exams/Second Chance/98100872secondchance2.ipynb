{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Healthcare Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13×131 Matrix{Float64}:\n",
       " -1.71231    -1.68596   -1.65962    …   1.65962      1.68596     1.71231\n",
       " -0.532913   -0.336813  -0.532913       2.40859     -0.532913    5.35009\n",
       " -0.69028    -0.228919  -0.69028        4.38469      0.232441   -0.228919\n",
       "  0.525609   -0.796403  -0.90657       -0.90657      0.0849384   0.96628\n",
       " -0.367785   -0.367785  -0.161888       0.455802    -0.367785   -0.161888\n",
       "  0.911436   -0.253186   0.911436   …  -1.09041     -0.959389   -0.103968\n",
       " -0.272174   -0.761938  -0.272174       3.89082     -0.517056    1.09916\n",
       "  0.0453112  -0.767808  -1.01174        1.10237     -0.117313    2.89123\n",
       " -0.218337    0.220571  -0.584094       2.34196      0.14742    -0.291489\n",
       "  1.72245    -0.839293  -0.562348      -0.00845635  -0.0776928   2.06864\n",
       "  0.863663   -0.304077   0.0560669  …   1.33294     -0.0530678   0.503519\n",
       " -0.218251   -0.218251  -0.218251      -0.218251    -0.218251   -0.218251\n",
       " -0.385867   -0.24267    0.330119       0.0437243   -0.24267     1.4757"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using DataFrames, CSV\n",
    "df = CSV.read(\"Quizhpc_2_Health Care Quality Assessment.csv\", DataFrame)\n",
    "\n",
    "xs = permutedims(Matrix{Float64}(df[:, 1:end-1]))\n",
    "ys = permutedims(df.PoorCare)\n",
    "\n",
    "# Normalization\n",
    "using Statistics: mean, std\n",
    "xs .-= mean(xs, dims=2)\n",
    "xs ./= std(xs, dims=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "model = Flux.Dense(size(xtrain)[1] => 1, σ)\n",
    "loss(x, y) = Flux.binarycrossentropy(model(x), y)\n",
    "optimiser = Flux.Descent()\n",
    "parameters = Flux.params(model)\n",
    "for _ in 1:10000\n",
    "    Flux.train!(loss, parameters, [(xs, ys)], optimiser)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives = 16\n",
      "True Negatives = 91\n",
      "False Positives = 7\n",
      "False Negatives = 17\n",
      "\n",
      "Precision = 0.6956521739130435\n",
      "Recall = 0.48484848484848486\n",
      "F1 Score = 0.5714285714285715\n"
     ]
    }
   ],
   "source": [
    "function confusion_matrix(predictions, ys)\n",
    "    predicted_positives = sum(predictions)\n",
    "    predicted_negatives = length(predictions) - predicted_positives\n",
    "    actual_positives = sum(ys)\n",
    "    actual_negatives = length(ys) - actual_positives\n",
    "\n",
    "    true_positives = sum(predictions .& ys)\n",
    "    false_positives = predicted_positives - true_positives\n",
    "    true_negatives = sum(.~predictions .& .~ys)\n",
    "    false_negatives = predicted_negatives - true_negatives\n",
    "\n",
    "    precision = true_positives / predicted_positives\n",
    "    recall = true_positives / actual_positives\n",
    "    f1score = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "    return (true_positives, true_negatives, false_positives, false_negatives,\n",
    "        precision, recall, f1score)\n",
    "end\n",
    "\n",
    "predictions = model(xs) .> 0.5\n",
    "(true_positives, true_negatives, false_positives, false_negatives,\n",
    "    precision, recall, f1score) = confusion_matrix(predictions, ys)\n",
    "\n",
    "println(\"True Positives = $true_positives\\nTrue Negatives = $true_negatives\\n\"\n",
    "    * \"False Positives = $false_positives\\nFalse Negatives = $false_negatives\\n\")\n",
    "println(\"Precision = $precision\\n\"\n",
    "    * \"Recall = $recall\\n\"\n",
    "    * \"F1 Score = $f1score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Logistic Regression Models\n",
    "## a.\n",
    "It does not matter for model 1, because no matter how we set the weights, the model is going to classify point 3 as Y = -1 (since there is no bias, P(Y=1) always equals 0). However, by changing the bias in model 2, it is possible to change the classification for point 3, so the labeling does matter for model 2.\n",
    "## b.\n",
    "If we define $\\mathcal{L}$ as the cost function,\n",
    "$$\\mathcal{L}(\\mathbf{w}, \\lambda; x^{(i)}, y^{(i)}) \\approx \\sum_i y^{(i)} \\mathbf{w}^T x^{(i)}\n",
    "-\\frac{\\lambda}{2}\\|\\mathbf{w}\\|^2.$$\n",
    "Since the cost function is the same for every component of $\\mathbf{w}$,\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial\\mathbf{w}} = \\sum_i y^{(i)} x^{(i)} - \\lambda\\mathbf{w}$$\n",
    "(keep in mind that $x$ is also a vector). By setting the derivative equal to zero, the MLE $\\mathbf{w}$ is obtained.\n",
    "$$\\mathbf{w} = \\frac{\\sum_i y^{(i)} x^{(i)}}{\\lambda}$$\n",
    "Therefore, $\\mathbf{w}$ gets smaller as $\\lambda$ increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Short Answer Questions\n",
    "## 3.\n",
    "FALSE; logistic regression is a method used for classification, not regression.\n",
    "## 4.\n",
    "TRUE; the logistic regression loss function can be used to train a neural network with sigmoid function nodes.\n",
    "## 5.\n",
    "b. Maximum Likelihood; least squares is used in linear regression, and Jaccard distance is completely irrelevant here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.0",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9e8427046da5c81670afb324f8be5c3e4e0517af65990874010837be676afee2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
